<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/index.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-04-09T16:52:43+02:00</updated><id>http://localhost:4000/index.xml</id><entry><title type="html">13 French Startups to Watch And Skyld Is On the List!</title><link href="http://localhost:4000/13-French-Startups-to-Watch-And-Skyld-Is-On-the-List" rel="alternate" type="text/html" title="13 French Startups to Watch And Skyld Is On the List!" /><published>2024-12-12T07:28:13+01:00</published><updated>2024-12-12T07:28:13+01:00</updated><id>http://localhost:4000/13-French-Startups-to-Watch-And-Skyld-Is-On-the-List</id><content type="html" xml:base="http://localhost:4000/13-French-Startups-to-Watch-And-Skyld-Is-On-the-List"><![CDATA[<p><strong><em>Skyld is featured in the prestigious list of “13 French startups to watch outside of Paris, according to VCs” by Sifted.</em></strong></p>

<p>This recognition highlights the innovative spirit and dedication of our team as we specialize in protecting on-device AI models, particularly for <strong>Edge deployments</strong>. At Skyld, we empower companies to deploy their AI models securely and confidently, ensuring both privacy and security are safeguarded.</p>

<p>With our cutting-edge solutions, businesses can:</p>
<ul>
  <li>Secure their intellectual property.</li>
  <li>Deploy AI models with confidence in untrusted environments</li>
  <li>Monetize AI models.</li>
</ul>

<p>A huge thank you to <strong>Anais Monlong</strong>, Venture Investor at IRIS, for highlighting us in Sifted within the vibrant tech ecosystem beyond the capital.</p>

<p><em>Discover the full article and explore the other startups shaping the future of innovation in France: <a href="https://sifted.eu/articles/french-startups-outside-paris">13 French startups to watch outside of Paris, according to VCs</a></em></p>

<p>© <em>Camelon Production.</em></p>]]></content><author><name>Skyld Labs</name></author><category term="News" /><summary type="html"><![CDATA[Skyld is featured in the prestigious list of “13 French startups to watch outside of Paris, according to VCs” by Sifted.]]></summary></entry><entry><title type="html">In The Spotlight: Marie Paindavoine Wins The Cyber Woman Award!</title><link href="http://localhost:4000/In-The-Spotlight-Marie-Paindavoine-Wins-the-Cyber-Woman-Award" rel="alternate" type="text/html" title="In The Spotlight: Marie Paindavoine Wins The Cyber Woman Award!" /><published>2024-12-12T07:28:13+01:00</published><updated>2024-12-12T07:28:13+01:00</updated><id>http://localhost:4000/In-The%20Spotlight-Marie-Paindavoine-Wins-the-Cyber-Woman-Award</id><content type="html" xml:base="http://localhost:4000/In-The-Spotlight-Marie-Paindavoine-Wins-the-Cyber-Woman-Award"><![CDATA[<p><strong>On December 10th in Paris, women in cybersecurity were celebrated!</strong></p>

<p>We’re thrilled to announce that <strong>Marie Paindavoine, founder and CEO of Skyld, won the European Cyber Woman Award in the Entrepreneur category.</strong></p>

<p>This award is a true recognition of our mission to bridge the gap between AI and cybersecurity. While AI is already widely used in cyber applications, the security of these algorithms is still an overlooked issue. Yet, they’re being applied in increasingly critical areas where trust and safety are key!</p>

<p>It was an evening filled with passion, talent, determination, and resilience—a chance to hear the powerful voices of women in the cyber industry.</p>

<p><strong>During the event, we were especially inspired by these talks:</strong></p>

<ul>
  <li>
    <p><strong>Sophie Viger,</strong> Managing Director at École 42 (engineering school specialised in coding) , who shared impressive data on the success of her efforts to bring more women into École 42, proving that it’s possible to move past the common excuse, “Women just don’t apply.”</p>
  </li>
  <li>
    <p><strong>Leslie Fornero</strong>, Marketing &amp; Communication Officer at Stoïk, emphasized the importance of communication and marketing in cybersecurity during attacks, stressing that it’s time to start blaming the perpetrator, not the victim.</p>
  </li>
  <li>
    <p><strong>Gabriela Belaid</strong>, Founder and Chair of the Think Tank Le Cercle Olympe de Gouges, who spoke candidly about the challenges of gender diversity in tech. She stressed the importance of actions that encourage women to step up and the role of showcasing female role models. But she also pointed out a major issue: <em>54% of women in tech report experiencing sexual harassment, showing the need for change on the men’s side as well.</em></p>
  </li>
</ul>

<p><strong>Congratulations to all the nominees and winners of the evening!</strong></p>

<p>And a special thank you to the CEFCYS team, led by <strong>Nacira Salvan</strong>, for organizing the 5th edition of the European Cyber Woman Awards and for their dedication to highlighting women’s talents in tech.</p>

<p><em>If you’d like to learn more about the event, check this link: <a href="https://www.itforbusiness.fr/cefcys-18-trophees-remis-aux-talents-feminins-de-la-cyber-86767">CEFCYS – 18 Awards Honoring Women in Cyber</a>.</em></p>]]></content><author><name>Skyld Labs</name></author><category term="News" /><summary type="html"><![CDATA[On December 10th in Paris, women in cybersecurity were celebrated!]]></summary></entry><entry><title type="html">Imagine Summit: A Day Focused on Innovation</title><link href="http://localhost:4000/Imagine-Summit-A-Day-Focused-on-Innovation" rel="alternate" type="text/html" title="Imagine Summit: A Day Focused on Innovation" /><published>2024-12-12T07:28:13+01:00</published><updated>2024-12-12T07:28:13+01:00</updated><id>http://localhost:4000/Imagine-Summit-A-Day-Focused-on-Innovation</id><content type="html" xml:base="http://localhost:4000/Imagine-Summit-A-Day-Focused-on-Innovation"><![CDATA[<p><strong>The 9th Imagine Summit just came to a close!</strong> Organized by <em>Le Poool and La French Tech Rennes St-Malo</em>, in collaboration with <em>Destination Rennes and Inria</em>, the Imagine Summit has established itself as the event to explore the latest innovations and projects shaping the Rennes ecosystem, our ecosystem.</p>

<p>This year’s theme, “<strong>Desirable Innovation</strong>” was perfectly aligned with what we do at Skyld, where innovation drives our mission to create reliable and sustainable AI.</p>

<p><strong>Here are the highlights of our day:</strong></p>

<ul>
  <li>
    <p>The Skyld team, represented by Victor Guyomard and Mathis Mauvisseau, had plenty of <strong>fascinating discussions</strong> with talented innovators and key players in a dynamic and diverse ecosystem.</p>
  </li>
  <li>
    <p>We had the honor of meeting <strong>Nathalie Appéré, Mayor of Rennes.</strong> We presented Skyld and our work in cybersecurity for artificial intelligence—a conversation that showcased how much local institutions actively support innovation.</p>
  </li>
  <li>
    <p>Our CEO and founder, Marie Paindavoine, shared our vision during a <strong>panel discussion on collaboration between startups and the Ministry of Armed Forces</strong>, focusing on trusted and sovereign digital technologies.</p>
  </li>
</ul>

<p>The local innovation scene here is diverse and combines industries like tech, food, and manufacturing, all supported by a committed and encouraging ecosystem . <strong>We’re proud to be part of it!</strong></p>]]></content><author><name>Skyld Labs</name></author><category term="News" /><summary type="html"><![CDATA[The 9th Imagine Summit just came to a close! Organized by Le Poool and La French Tech Rennes St-Malo, in collaboration with Destination Rennes and Inria, the Imagine Summit has established itself as the event to explore the latest innovations and projects shaping the Rennes ecosystem, our ecosystem.]]></summary></entry><entry><title type="html">GenerationAI: A Vision of AI Beyond Algorithms</title><link href="http://localhost:4000/GenerationAI-A-Vision-of-AI-Beyond-Algorithms" rel="alternate" type="text/html" title="GenerationAI: A Vision of AI Beyond Algorithms" /><published>2024-12-12T07:28:13+01:00</published><updated>2024-12-12T07:28:13+01:00</updated><id>http://localhost:4000/GenerationAI-A-Vision-of-AI-Beyond-Algorithms</id><content type="html" xml:base="http://localhost:4000/GenerationAI-A-Vision-of-AI-Beyond-Algorithms"><![CDATA[<p><strong><em>On December 3rd, our CEO Marie Paindavoine was at GenerationAI Paris 2024, giving a presentation on “Model Extraction: Why You Should Care and How to Protect Yourself.” This topic is important for understanding the risks of AI model extraction and how to protect against it.</em></strong></p>

<p>GenerationAI was more than just a technical conference. It sparked important conversations about the social, environmental, and philosophical issues related to AI.</p>

<p>Indeed, AI needs gradient descent, GPU power, training epochs, fine-tuning, knowledge distillation, loss function optimization, and many other technical things.</p>

<p><strong>But AI also needs:</strong></p>

<ul>
  <li>
    <p><strong>Psychology</strong> - Do we love LLMs because they confirm our own confirmation biases?</p>
  </li>
  <li>
    <p><strong>Literature -</strong> How can writing help us imagine what we want and what we do not want from our AI use?</p>
  </li>
  <li>
    <p><strong>Philosophy</strong> - Is AI at our service, by providing data insights into our life (after all, we can only improve what we measure), or are we at the service of AI, feeding the tech giants with every aspect of our life?</p>
  </li>
  <li>
    <p><strong>Politics</strong> - Should the hyperpersonalization pushed by AI reflect on public policies?</p>
  </li>
  <li>
    <p><strong>Environmental sciences</strong> - Is AI always worth its environmental cost? Can AI help us fight climate change?</p>
  </li>
</ul>

<p>These questions don’t have definitive answers, but they’ve sparked some really interesting debates, with best-in-class speakers!
The technical aspect of AI was not left behind of course, with amazing sessions mixing GenAI, computer vision and on-device AI.
We’re honored to have been part of this event, it was a huge success!</p>]]></content><author><name>Skyld Labs</name></author><category term="News" /><summary type="html"><![CDATA[On December 3rd, our CEO Marie Paindavoine was at GenerationAI Paris 2024, giving a presentation on “Model Extraction: Why You Should Care and How to Protect Yourself.” This topic is important for understanding the risks of AI model extraction and how to protect against it.]]></summary></entry><entry><title type="html">New Deployments, New Threats: How To Protect Local AI Models From Reverse Engineering?</title><link href="http://localhost:4000/New-Deployments-New-Threats-How-To-Protect-Local-Ai-Models-From-Reverse-Engineering" rel="alternate" type="text/html" title="New Deployments, New Threats: How To Protect Local AI Models From Reverse Engineering?" /><published>2024-09-16T07:17:13+02:00</published><updated>2024-09-16T07:17:13+02:00</updated><id>http://localhost:4000/New-Deployments-New-Threats-How-To-Protect-Local-Ai-Models-From-Reverse-Engineering</id><content type="html" xml:base="http://localhost:4000/New-Deployments-New-Threats-How-To-Protect-Local-Ai-Models-From-Reverse-Engineering"><![CDATA[<h4>Introduction: The Rise of Local AI</h4>

<p>Deep Learning (DL) models have become a cornerstone of many software applications, powering features such as access control, health diagnostics, KYC (Know Your Customer), environmental analysis, and voice and sound recognition. Traditionally, these models were hosted on cloud servers, but a new trend has emerged: a local deployment closer to the data source. This deployment can be on existing devices like cars or smartphones, on dedicated hardware, or, of particular concern here, on on-premises servers. This shift promises faster response times, better user privacy, and reduced cloud infrastructure costs. However, it also introduces a major security challenge: <strong>the threat of model theft and associated intellectual property.</strong></p>

<p><em>As DL models become integral to application functionality, protecting them is crucial. In this article, we’ll cover the basics of model reverse engineering methodologies and associated protection techniques.</em></p>

<h4>The Growing Threat of Model Theft</h4>

<p>DL models represent significant investments for companies. These models are created using large datasets, require specialized expertise, and demand substantial computational resources for training. Data is often called the <strong>“oil of the 21st century,”</strong>, however, the models used to process them are also valuable. If these models are stolen, competitors can replicate an application’s features without bearing the development costs, leading to significant financial losses and reducing the application’s competitive edge.</p>

<p>Moreover, many DL models perform sensitive tasks, such as biometric authentication or malware detection. If malicious actors gains access to these models, they can conduct white-box adversarial attacks, potentially fooling the models more effectively. This makes securing these models in uncontrolled environments critically important.</p>

<p>Finally, if the model is intended for monetization, for example through licensing, protecting it is an effective technical measure to limit access to the model over time and/or to a restricted number of machines or individuals.</p>

<h4>How to Reverse Engineer AI Models?</h4>

<p>Before starting, it’s essential to know how the DL model is deployed. There are generally two options: <strong>models can be stored as files, or compiled into binaries specialized for the target hardware.</strong></p>

<p>The first possible attack is a static code analysis. After decompilation, using tools like <strong>Ghidra</strong> or <strong>IDA</strong>, an attacker will search for files with extensions such as <strong>.onnx, .tflite, or .h5,</strong> which are common formats for on-device AI models. Lists of these formats can be found using model viewers like <strong>Netron</strong> to automate the attack. It’s also possible to refine the analysis by using magic numbers in file headers to confirm that the file is indeed a model, even if the name or extension has been changed. Once the model is identified, it can be extracted. The attacker can then run unauthorized copies of the software or even reuse the model in their application.</p>

<p>If the file’s entropy is above a certain threshold, it’s likely that the developer has encrypted the model. However, this can be bypassed using dynamic analysis. Debugging tools like gdb can be used to run the code and monitor framework functions that load models into memory before execution. Then, the function can be hooked, meaning a script is injected to modify the loading function’s behavior and return the model in plain text. Tools like Frida can facilitate this process across various execution environments.</p>

<p>Code obfuscation makes these attacks more challenging by making the decompiled code harder to read and understand. This increases the time and effort required to extract a model. While this may protect the model’s confidentiality against attackers with limited resources, it won’t prevent unauthorized reuse of the model.</p>

<h4>How Developers Can Protect Their Models?</h4>

<p>To protect DL models, developers need to implement more stringent security measures than just encryption or obfuscation, whether combined or not. There are at least two desirable properties for an AI model in terms of security:</p>

<ul>
  <li>
    <p><strong>Model Confidentiality:</strong> Depending on the case—whether the model is fine-tuned from an open-source architecture or an innovative one—this could mean confidentiality of the model’s parameters (weights and biases) or the model’s architecture (layer types, layer sequence). Model confidentiality must withstand both static and dynamic attacks as described earlier.</p>
  </li>
  <li>
    <p><strong>License Enforcement:</strong> This involves having a technical solution to enforce the model’s usage terms and prevent unauthorized reuse. This could involve time-limited access or restrictions on the number of devices on which the model can be deployed.</p>
  </li>
</ul>

<p>In ShadowNet: <a href="https://www.computer.org/csdl/proceedings-article/sp/2023/933600b489/1OXH83c7EYM">ShadowNet: A Secure and Efficient On-device Model Inference System for Convolutional Neural Networks (computer.org)</a> , the authors propose mathematical modifications to models to ensure weight transformation. This protection is valid both at rest and during execution since all calculations are performed on modified weights or within secure enclaves. No clear weights are sent to unsecured memory.</p>

<p>Other papers,s such as <a href="https://arxiv.org/abs/2306.06112">[2306.06112] ModelObfuscator: Obfuscating Model Information to Protect Deployed ML-based Systems (arxiv.org)</a> suggest solutions based on custom machine learning frameworks for each model to protect the model’s architecture.</p>

<p>These academic solutions still face significant deployment challenges, either due to the need to control the hardware on which the algorithm is deployed or because they create a dependency on a modified framework that might not receive updates from the main framework.</p>

<h4>Conclusion: The Future of Model Security</h4>

<p>As the trend of on-device inference grows, risks will only increase. In this context, Skyld, a spin-off of Inria and based at Station F, offers a solution that protects models at rest, during execution, and without relying on hardware. This solution is based on mathematical transformations of the model to preserve weight confidentiality.</p>

<p><em>Finding a solution that preserves both weight and architecture confidentiality without altering the machine learning framework remains an open problem, presenting an exciting challenge for cybersecurity researchers.</em></p>]]></content><author><name>Marie Paindavoine</name></author><category term="ML security" /><category term="article" /><summary type="html"><![CDATA[Introduction: The Rise of Local AI]]></summary></entry><entry><title type="html">Skyld At VivaTech 2024</title><link href="http://localhost:4000/Vivatech-2024" rel="alternate" type="text/html" title="Skyld At VivaTech 2024" /><published>2024-08-29T08:28:13+02:00</published><updated>2024-08-29T08:28:13+02:00</updated><id>http://localhost:4000/Vivatech-2024</id><content type="html" xml:base="http://localhost:4000/Vivatech-2024"><![CDATA[<p>VivaTech opened its doors on Wednesday, May 22, 2024, and ran until May 25. This 8th edition brought together technology enthusiasts and innovators at Porte de Versailles, Paris.</p>

<p>Artificial intelligence was the main topic. So, the Skyld team was delighted to be there. 
The first day was full of highlights.</p>

<p>▶ First, we had the honor of being present at the <strong>DFKI booth</strong>. A big thank you to them for their warm welcome.</p>

<p>▶ We were also privileged to receive a visit from the <strong>CEO of INRIA</strong>, Bruno Sportisse, who congratulated us on the progress of the company.</p>

<p>▶ Additionally, it was a real pleasure to <strong>meet HopeValley</strong>, who believed in us for our first POC. It’s always rewarding to see people who supported Skyld from the very beginning.</p>

<p>Thursday, we were chosen to pitch at the <strong>European Deeptech Meetup</strong>.  Skyld was one of 50 deep-tech start-ups chosen from over 200 applicants. The event supports start-ups in healthcare, digital, and industry.</p>

<p>Throughout the event, we were proud to be there with our <strong>Brittany community</strong>. Many booths showcased the region’s ecosystem. 
VivaTech is the must-attend event for technological innovation.</p>

<p><em>And if we missed each other this year, we hope to see you next year!</em></p>

<p><img src="../../assets/images/blog/news/Vivatech collage.webp" alt="alt text" class="centered" /></p>]]></content><author><name>Skyld Labs</name></author><category term="News" /><summary type="html"><![CDATA[VivaTech opened its doors on Wednesday, May 22, 2024, and ran until May 25. This 8th edition brought together technology enthusiasts and innovators at Porte de Versailles, Paris.]]></summary></entry><entry><title type="html">Skyld Joins The New Season Of Thales Cyber@Station F !</title><link href="http://localhost:4000/Skyld-Joins-The-New-Season-of-Thales-Cyber@StationF!" rel="alternate" type="text/html" title="Skyld Joins The New Season Of Thales Cyber@Station F !" /><published>2024-08-29T08:28:13+02:00</published><updated>2024-08-29T08:28:13+02:00</updated><id>http://localhost:4000/Skyld-Joins-The-New-Season-of-Thales-Cyber@StationF!</id><content type="html" xml:base="http://localhost:4000/Skyld-Joins-The-New-Season-of-Thales-Cyber@StationF!"><![CDATA[<p>The Thales Cyber@Station F acceleration program is a great opportunity for Sklyd to benefit from Thales’ expertise and ecosystem.</p>

<p>This strategic partnership will enable us to strengthen our position in the cybersecurity field, while benefiting from many advantages :</p>

<p>✔️ <strong>Access new ecosystems and customers for our on-device AI model cybersecurity solution</strong>: Joining the program gives us access to a new ecosystem. We have the opportunity to expand our network, meet key players and open up new collaboration opportunities.</p>

<p>✔️ <strong>Benefit from the expertise of technical and business coaches</strong>: One of the key benefits of this program is the personalized support provided by Thales technical and business coaches. Their expertise will enable us to refine our sales strategy to more effectively align it with market needs.</p>

<p>✔️ <strong>Integrate a great promotion of A-level cybersecurity startups</strong>: By joining Cyber@Station F, Sklyd also has the opportunity to be part of an elite promotion of cybersecurity startups such as Defants, Dfns, Dynatrust, Octopize and Uncovery. This immersion in a dynamic and innovative ecosystem fosters collaboration and the creation of synergies between startups, contributing to the emergence of ever more effective cybersecurity solutions.</p>

<p>Thanks to Thales for its confidence in the Skyld team and for this opportunity to join a fast-growing ecosystem.</p>]]></content><author><name>Skyld Labs</name></author><category term="News" /><summary type="html"><![CDATA[The Thales Cyber@Station F acceleration program is a great opportunity for Sklyd to benefit from Thales’ expertise and ecosystem.]]></summary></entry><entry><title type="html">We’re Now Part Of The NVIDIA’s Inception Program For Startups.</title><link href="http://localhost:4000/Skyld-Joins-NVIDIA's-Inception-Program-For-Startups" rel="alternate" type="text/html" title="We’re Now Part Of The NVIDIA’s Inception Program For Startups." /><published>2024-08-29T08:28:13+02:00</published><updated>2024-08-29T08:28:13+02:00</updated><id>http://localhost:4000/Skyld-Joins-NVIDIA&apos;s-Inception-Program-For-Startups</id><content type="html" xml:base="http://localhost:4000/Skyld-Joins-NVIDIA&apos;s-Inception-Program-For-Startups"><![CDATA[<p><em>We are excited to announce that we have been accepted into NVIDIA’s Inception Program, which supports start-ups in AI and data science. The program offers tools, advanced technologies, and opportunities to accelerate our development.</em></p>

<h4>What Are The Benefits Of The Inception Program?</h4>

<p>NVIDIA’s Inception program offers exclusive access to NVIDIA’s expertise and technologies in deep learning and data science. Start-ups also benefit from networking opportunities with investors and visibility on a broad market.</p>

<p>The program is adapted to deep tech start-ups at different stages of maturity and offers them resources such as cloud credits, marketing support and training on NVIDIA platforms.</p>

<p>This initiative is part of NVIDIA’s wider effort to support the ecosystem around AI and machine learning, promoting innovation and development in these crucial fields.</p>

<h4>Support Throughout The Start-up Lifecycle!</h4>

<p>NVIDIA’s Inception program supports all stages of a start-up’s lifecycle and works closely with its members to provide them with the best technical tools, the latest resources and opportunities to connect with investors.</p>

<p>Skyld is delighted to have joined this program and looks forward to taking advantage of the many benefits on offer to continue to innovate and grow.</p>

<p><em>Joining NVIDIA’s Inception program is another step forward!</em></p>]]></content><author><name>Skyld Labs</name></author><category term="News" /><summary type="html"><![CDATA[We are excited to announce that we have been accepted into NVIDIA’s Inception Program, which supports start-ups in AI and data science. The program offers tools, advanced technologies, and opportunities to accelerate our development.]]></summary></entry><entry><title type="html">In Wavestone’s Radar!</title><link href="http://localhost:4000/Skyld-In-Wavestone's-Radar" rel="alternate" type="text/html" title="In Wavestone’s Radar!" /><published>2024-08-29T08:28:13+02:00</published><updated>2024-08-29T08:28:13+02:00</updated><id>http://localhost:4000/Skyld-In-Wavestone&apos;s-Radar</id><content type="html" xml:base="http://localhost:4000/Skyld-In-Wavestone&apos;s-Radar"><![CDATA[<p><em>Skyld is proud to be listed on the Wavestone radar of French cybersecurity start-ups 2024 in the Artificial Intelligence category. With 168 startups and 42 scale-ups, the French cybersecurity innovation ecosystem is continuing to grow and is showing that it has successfully turned the corner on Artificial Intelligence (AI).</em></p>

<p>For 10 years now, Wavestone has been updating its annual forecasting tool, the ‘CISO Radar’, which brings together all the key issues for the cybersecurity and operational resilience sectors.</p>

<p><strong>Here are this year’s key elements</strong>:</p>

<p>▶ <strong>Expanding the ecosystem</strong>: Partnerships between startups and large companies are multiplying, fostering innovation and the development of more robust security solutions. With 168 startups and 42 scale-ups, our field is booming!</p>

<p>▶ <strong>AI in the spotlight</strong>: Changing legislative frameworks are forcing cybersecurity players to adapt quickly, stimulating innovation and technical excellence. AI technology is becoming a central pillar in our security strategies.</p>

<p>▶ <strong>Sustained growth</strong>: Despite a slowdown in investment, the outlook for growth remains positive. And with the shortage of cybersecurity talent, many initiatives are being put in place to train the next generation of experts.</p>

<p>A big thank you to Wavestone and Bpifrance for this recognition, and a nod to all those who have supported us in this adventure!</p>]]></content><author><name>Skyld Labs</name></author><category term="News" /><summary type="html"><![CDATA[Skyld is proud to be listed on the Wavestone radar of French cybersecurity start-ups 2024 in the Artificial Intelligence category. With 168 startups and 42 scale-ups, the French cybersecurity innovation ecosystem is continuing to grow and is showing that it has successfully turned the corner on Artificial Intelligence (AI).]]></summary></entry><entry><title type="html">Attack On AI Models: What You Need to Know!</title><link href="http://localhost:4000/Attack-On-AI-models-What-You-Need-to-Know" rel="alternate" type="text/html" title="Attack On AI Models: What You Need to Know!" /><published>2024-08-27T07:17:13+02:00</published><updated>2024-08-27T07:17:13+02:00</updated><id>http://localhost:4000/Attack-On-AI-models-What-You-Need-to-Know</id><content type="html" xml:base="http://localhost:4000/Attack-On-AI-models-What-You-Need-to-Know"><![CDATA[<p><em>Artificial intelligence is used in many fields, including autonomous cars and facial recognition. Every AI application has a carefully designed and trained model. But did you know that these models can be the target of malicious attacks? This article looks at the risks to AI models and how to protect them.</em></p>

<h3 id="understanding-ai-models-and-their-vulnerability"><strong>Understanding AI Models and Their Vulnerability</strong></h3>

<p>When an AI model is deployed, it is stored in a file containing all the necessary structure and parameters, enabling the model to produce the expected results.</p>

<p>Picture this : you’re building a house. You have a plan showing where to place each wall, window, and what material to use. In the same way, an AI model file specifies the types of neural layers, activation functions, weights and biases - all elements that determine how the model works.</p>

<p>But what happens if this file isn’t properly protected? Let’s continue with our example.</p>

<p>Now imagine that your house has no fence or security system. Any malicious person could enter, examine the interior layout, copy the plans and even steal valuable items. Similarly, an unprotected AI model file is vulnerable. It can be easily accessible to attackers, who could then extract sensitive information such as weights and biases, and use this information for unauthorized activities, such as reverse engineering.</p>

<p>In a previous article, we demonstrated how easy it is, in practice, to extract this type of file from an AI model : <a href="https://www.sstic.org/2023/presentation/your_mind_is_mine_how_to_automatically_steal_dl_models_from_android_apps/" title="https://www.sstic.org/2023/presentation/your_mind_is_mine_how_to_automatically_steal_dl_models_from_android_apps/">SSTIC2023 » Présentation » Your Mind is Mine: How to Automatically Steal DL Models From Android Apps - Marie Paindavoine, Maxence Despres, Mohamed Sabt</a></p>

<h3 id="why-protecting-your-ai-models-is-important"><strong>Why Protecting Your AI Models Is Important</strong></h3>

<p>It is crucial to safeguard your AI models in today’s competitive digital landscape. By protecting your AI model files, you can maintain your competitive edge and safeguard your intellectual property.</p>

<p>Failing to secure these files leaves your organization vulnerable to potential attacks.</p>

<p>In addition to straightforward reverse engineering, an adversary may employ more sophisticated techniques, such as adversarial examples or model inversion attacks, to exploit inherent vulnerabilities in the model. In particular, white-box attacks can be devastating, as they give the attacker a complete view of the model and its parameters.</p>

<h3 id="security-solutions"><strong>Security Solutions</strong></h3>

<p>In this context, solutions like those offered by Skyld become essential.</p>

<p>Skyld provides a solution for securing AI models, both at rest and during execution. Our approach prevents the extraction of information about model parameters, ensuring that the crucial details needed to understand and reproduce the model remain protected.</p>

<p>AI model security is not an option, but a necessity for all companies seeking to maintain their market position and protect their intellectual property.</p>

<p><strong>Don’t leave your <em>“home”</em> unprotected-make sure your AI models are secure today!</strong></p>]]></content><author><name>Skyld Labs</name></author><category term="ML security" /><category term="article" /><summary type="html"><![CDATA[Artificial intelligence is used in many fields, including autonomous cars and facial recognition. Every AI application has a carefully designed and trained model. But did you know that these models can be the target of malicious attacks? This article looks at the risks to AI models and how to protect them.]]></summary></entry></feed>